{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "fe13b8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "0369ce80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing haarcascadexml file it is basically a classifier\n",
    "classifier=cv.CascadeClassifier(\"haarcascade_frontalface_default.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "df5838c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<CascadeClassifier 00000212A52B7D90>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "eb4cc60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv.imread(\"classroom.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "2ffd05eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 93, 130, 168],\n",
       "        [ 94, 131, 169],\n",
       "        [ 94, 131, 169],\n",
       "        ...,\n",
       "        [ 21,  45,  33],\n",
       "        [ 21,  45,  33],\n",
       "        [ 21,  45,  33]],\n",
       "\n",
       "       [[ 92, 126, 162],\n",
       "        [ 92, 126, 162],\n",
       "        [ 92, 126, 162],\n",
       "        ...,\n",
       "        [ 21,  45,  33],\n",
       "        [ 21,  45,  33],\n",
       "        [ 21,  45,  33]],\n",
       "\n",
       "       [[113, 140, 174],\n",
       "        [113, 140, 174],\n",
       "        [113, 140, 174],\n",
       "        ...,\n",
       "        [ 21,  45,  33],\n",
       "        [ 21,  45,  33],\n",
       "        [ 21,  45,  33]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 11,  23,   5],\n",
       "        [ 12,  24,   6],\n",
       "        [ 13,  25,   7],\n",
       "        ...,\n",
       "        [ 79, 120, 145],\n",
       "        [ 76, 117, 142],\n",
       "        [ 74, 115, 140]],\n",
       "\n",
       "       [[  9,  20,  12],\n",
       "        [  9,  20,  12],\n",
       "        [ 10,  21,  13],\n",
       "        ...,\n",
       "        [ 76, 119, 146],\n",
       "        [ 72, 115, 142],\n",
       "        [ 69, 112, 139]],\n",
       "\n",
       "       [[  9,  17,  16],\n",
       "        [  9,  17,  16],\n",
       "        [  9,  18,  15],\n",
       "        ...,\n",
       "        [ 75, 118, 145],\n",
       "        [ 72, 115, 142],\n",
       "        [ 67, 110, 137]]], dtype=uint8)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img  #we need to pass this image to classifier so that classifier can detect the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "350b3b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "faces=classifier.detectMultiScale(img,1.06,3) #2nd_parameteris scaling factorless the value of scale more faces will be detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "12bc0400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[709,  22,  43,  43],\n",
       "       [232,  31,  39,  39],\n",
       "       [746, 366,  69,  69],\n",
       "       [260, 158,  67,  67],\n",
       "       [332,  54,  38,  38],\n",
       "       [ 47,  51,  47,  47],\n",
       "       [584,  48,  57,  57],\n",
       "       [  2, 215,  35,  35],\n",
       "       [538, 169,  48,  48],\n",
       "       [419, 182,  82,  82],\n",
       "       [741,  56,  60,  60],\n",
       "       [145,  59,  50,  50],\n",
       "       [690,  82,  28,  28],\n",
       "       [446,  78,  70,  70],\n",
       "       [612, 105,  67,  67],\n",
       "       [137,  95,  66,  66]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faces #FACES HAVING CO-ORDINATES OF ALL THE FACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "08074fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for(x,y,w,h) in faces:\n",
    "    cv.rectangle(img,(x,y),(x+w,y+h),(0,180,0),2) #taking eacg face at a time and after taht drawing a rectangle last parameter \n",
    "                                                  #thickness of rectangle and last secong is color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "26e7bded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.imwrite(\"detected1 image.png\",img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "bac50703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to crop the detected image\n",
    "face=img[y:y+h, x:x+w,:]\n",
    "cv.imwrite(\"cropimage.png\",face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77e0258",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
